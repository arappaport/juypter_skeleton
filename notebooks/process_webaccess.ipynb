{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "from _ast import Load\n",
    "\n",
    "# Simple notebook to process generic webaccess files. \n",
    "\n",
    "Assumptions\n",
    "1. There are one or more csv files with access logs in the given directory. \n",
    "1. Each file can be big - 20k or more rows to process\n",
    "\n",
    "Approach: \n",
    "1. Load each csv in the named directory with the given file spec (glob style)\n",
    "1. combine as we go into a master df.     If the size becomes too large . then process each file one at a time and collect the stats as we go. \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from datetime import date, timedelta\n",
    "import numpy as np\n",
    "from datetime import date, datetime\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import pytz\n",
    "from df_util import check_df\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format=\"%(message)s\")\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "LOGGER.debug(\"log level = %s\", str(LOGGER.getEffectiveLevel()))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#files to load: \n",
    "if False:\n",
    "    FILE_PATTERN=\"../data/webaccess/web_access_*.csv\"\n",
    "    #Columns that must be in the CSV. \n",
    "    REQUIRED_COLUMNS=['date','user','url']\n",
    "else:\n",
    "\n",
    "    FILE_PATTERN=\"../../../sample_webaccess_data/*UTC_web_log*csv\"\n",
    "    REQUIRED_COLUMNS=['Event Time', 'User', 'URL', 'Cloud Application Class', 'Cloud Application', \n",
    "                  'URL Class','URL Super Category', 'URL Category', 'Threat Category', 'Threat Name',\n",
    "                  'Location', 'Department', \n",
    "                  #'Protocol', 'Blocked Policy Type',\n",
    "                  'Upload File Name']\n",
    "    \n",
    "\n",
    "\n",
    "REQUIRED_VALUES=REQUIRED_COLUMNS\n",
    "\n",
    "DATE_AS_OF=date.fromisoformat('2023-06-01') #Date for analysis\n",
    "\n",
    "#For data visualization - date range sizes\n",
    "DATE_GROUP_DAYS=30\n",
    "CUTOFF_DAYS=90\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#  Determine which  files that meet the filespec - this doesn't load them\n",
    "file_names = glob.glob(FILE_PATTERN)\n",
    "if len(file_names) == 0:\n",
    "    msg = f\"ERROR: No file names found for pattern (\\\"{FILE_PATTERN}\\\". Stopping\"\n",
    "    LOGGER.error(msg)\n",
    "    raise ValueError(msg)\n",
    "\n",
    "LOGGER.info(\"%d files met the file pattern:[%s]\", len(file_names), FILE_PATTERN)\n",
    "print(file_names)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df = None\n",
    "\n",
    "#TODO - skip any non value rows from top of CSV. \n",
    "for i, file_name in enumerate(file_names):\n",
    "    df_tmp = pd.read_csv(file_name)\n",
    "    LOGGER.debug(\"file %d:[%s]: Loaded %d rows\", i, file_name, len(df_tmp))\n",
    "\n",
    "    if df is None:\n",
    "        df = df_tmp\n",
    "    else:\n",
    "        df = pd.concat([df, df_tmp], axis=0)\n",
    "        LOGGER.debug(\" after concat: df len= %d rows\", len(df))\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "#check dataframe for missing blocks.  err is empty if no errors - otherwise an err str\n",
    "err = check_df(df, required_columns=REQUIRED_COLUMNS, required_values=REQUIRED_VALUES)\n",
    "if err:\n",
    "    print(str(err))\n",
    "    Exception(err)\n",
    "    \n",
    "LOGGER.info(\"Loaded %d clean rows\", len(df))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df.head()\n",
    "\n",
    "# Assuming date_string is your datetime string\n",
    "date_string = \"March 22, 2024 9:00:25 PM PDT\"\n",
    "\n",
    "# Replace PDT with UTC-7\n",
    "date_string = date_string.replace(\"PDT\", \"UTC-7\")\n",
    "\n",
    "# Use pandas to parse the string into a datetime\n",
    "dt = pd.to_datetime(date_string)\n",
    "\n",
    "# Print the datetime\n",
    "print(dt)\n",
    "\n",
    "dt_utc = dt.astimezone(pytz.UTC)\n",
    "print(dt_utc)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Parse the string into a datetime object\n",
    "#  Assume the date is in a format like this: \"March 22, 2024 9:00:25 PM PDT\"\n",
    "def convert_date(s:str) ->str:     \n",
    "    # Replace PDT with UTC-7\n",
    "    s = s.replace(\"PDT\", \"UTC-7\")\n",
    "    dt =  pd.to_datetime(s)\n",
    "    # Convert the datetime object to UTC\n",
    "    dt_utc = dt.astimezone(pytz.UTC)\n",
    "    return dt_utc\n",
    "\n",
    "df['datetime'] = df['Event Time'].apply(convert_date)\n",
    "df['date']  = pd.to_datetime(df['datetime'], format='%Y-%m-%d').dt.date\n",
    "\n",
    "\n",
    "LOGGER.info(\"Date-range min: %s\", df['datetime'].min())\n",
    "LOGGER.info(\"Date-range max: %s\", df['datetime'].max())\n",
    "\n",
    "LOGGER.info(\"Date-range min: %s\", df['date'].min())\n",
    "LOGGER.info(\"Date-range max: %s\", df['date'].max())\n",
    "\n",
    "df.head()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def count_by(col:str, df:pd.DataFrame)->pd.DataFrame:\n",
    "    _df = df.groupby([col]).size().reset_index(name='count')\n",
    "    _df.columns = [col, 'count']\n",
    "    _df.sort_values(by='count', ascending=False, inplace=True)\n",
    "    return _df"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df_url = count_by('URL', df)\n",
    "df_url.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df_app = count_by('Cloud Application', df)\n",
    "df_app.head()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df_appclass = count_by('Cloud Application Class', df)\n",
    "df_appclass.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "################################\n",
    "# URL Access by user\n",
    "#for each URL - count the number of access by each unique user.    \n",
    "#  this allows multiple per users per day. \n",
    "df_url_by_user = df.groupby(['user', 'url']).size().reset_index(name='count')\n",
    "df_url_by_user.columns = ['user', 'url', 'count']\n",
    "df_url_by_user.sort_values(by='count', ascending=False, inplace=True)\n",
    "df_url_by_user.head(10)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0 (main, Oct 25 2022, 13:57:33) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
