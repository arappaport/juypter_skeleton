{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "from _ast import Load\n",
    "\n",
    "# Simple notebook to process generic webaccess files. \n",
    "\n",
    "Assumptions\n",
    "1. There are one or more csv files with access logs in the given directory. \n",
    "1. Each file can be big - 20k or more rows to process\n",
    "\n",
    "Approach: \n",
    "1. Load each csv in the named directory with the given file spec (glob style)\n",
    "1. combine as we go into a master df.     If the size becomes too large . then process each file one at a time and collect the stats as we go. \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from datetime import date, timedelta\n",
    "import numpy as np\n",
    "from datetime import date, datetime\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "from df_util import check_df\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format=\"%(message)s\")\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "LOGGER.debug(\"log level = %s\", str(LOGGER.getEffectiveLevel()))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#files to load: \n",
    "FILE_PATTERN=\"../data/webaccess/web_access_*.csv\"\n",
    "\n",
    "#Columns that must be in the CSV. \n",
    "REQUIRED_COLUMNS=['date','user','url']\n",
    "REQUIRED_VALUES=REQUIRED_COLUMNS\n",
    "\n",
    "\n",
    "DATE_AS_OF=date.fromisoformat('2023-06-01') #Date for analysis\n",
    "\n",
    "#For data visualization - date range sizes\n",
    "DATE_GROUP_DAYS=30\n",
    "CUTOFF_DAYS=90\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#  Determine which  files that meet the filespec - this doesn't load them\n",
    "file_names = glob.glob(FILE_PATTERN)\n",
    "if len(file_names) == 0:\n",
    "    msg = f\"ERROR: No file names found for pattern (\\\"{FILE_PATTERN}\\\". Stopping\"\n",
    "    LOGGER.error(msg)\n",
    "    raise ValueError(msg)\n",
    "\n",
    "LOGGER.info(\"%d files met the file pattern:[%s]\", len(file_names), FILE_PATTERN)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = None\n",
    "\n",
    "#TODO - skip any non value rows from top of CSV. \n",
    "for i, file_name in enumerate(file_names):\n",
    "    df_tmp = pd.read_csv(file_name)\n",
    "    LOGGER.debug(\"file %d:[%s]: Loaded %d rows\", i, file_name, len(df_tmp))\n",
    "\n",
    "    if df is None:\n",
    "        df = df_tmp\n",
    "    else:\n",
    "        df = pd.concat([df, df_tmp], axis=0)\n",
    "        LOGGER.debug(\" after concat: df len= %d rows\", len(df))\n",
    "    df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#check dataframe for missing blocks.  err is empty if no errors - otherwise an err str\n",
    "err = check_df(df, required_columns=REQUIRED_COLUMNS, required_values=REQUIRED_VALUES)\n",
    "if err:\n",
    "    print(str(err))\n",
    "    Exception(err)\n",
    "    \n",
    "LOGGER.info(\"Loaded %d clean rows\", len(df))"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#convert dates\n",
    "df['date']  = pd.to_datetime(df['date'], format='%Y-%m-%d').dt.date\n",
    "LOGGER.info(\"Date-range min: %s\", df['date'].min())\n",
    "LOGGER.info(\"Date-range max: %s\", df['date'].max())\n",
    "\n",
    "dmin = df['date'].min()\n",
    "#df['days_since'] = df['date'].apply(lambda x: (x-dmin).days)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "################################\n",
    "# URL Access - count each unique access to the url\n",
    "df_url_count = df.groupby(['url']).size().reset_index(name='count')\n",
    "df_url_count.columns = ['url', 'count']\n",
    "\n",
    "df_url_count.sort_values(by='count', ascending=False, inplace=True)\n",
    "df_url_count.head(10)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "################################\n",
    "# URL Access by user\n",
    "#for each URL - count the number of access by each unique user.    \n",
    "#  this allows multiple per users per day. \n",
    "df_url_by_user = df.groupby(['user', 'url']).size().reset_index(name='count')\n",
    "df_url_by_user.columns = ['user', 'url', 'count']\n",
    "df_url_by_user.sort_values(by='count', ascending=False, inplace=True)\n",
    "df_url_by_user.head(10)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0 (main, Oct 25 2022, 13:57:33) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
