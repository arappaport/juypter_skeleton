{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#Basic notebook with a few juypter examples\n",
    "\n",
    "\n",
    "# Metrics to calc\n",
    "\n",
    "# Users that haven't purchased in a while\n",
    "# Last purchase per user - any product\n",
    "\n",
    "#Last purchase per user - each product\n",
    "#  * somehow include no purchases - for ones that they have been assigned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T14:33:05.192636Z",
     "start_time": "2023-12-23T14:33:05.188771Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mlogging\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdatetime\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m date, timedelta\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from datetime import date, timedelta\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format=\"%(message)s\")\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "LOGGER.debug(\"log level = %s\", str(LOGGER.getEffectiveLevel()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T14:33:05.712483Z",
     "start_time": "2023-12-23T14:33:05.684172Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'date' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m DATA_PATH\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./data/purchases.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 2\u001B[0m DATE_AS_OF\u001B[38;5;241m=\u001B[39m\u001B[43mdate\u001B[49m\u001B[38;5;241m.\u001B[39mfromisoformat(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m2023-06-01\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;66;03m#Date for analysis\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m#For data visualization - date range sizes\u001B[39;00m\n\u001B[1;32m      4\u001B[0m DATE_GROUP_DAYS\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m30\u001B[39m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'date' is not defined"
     ]
    }
   ],
   "source": [
    "DATA_PATH=\"./data/purchases.csv\"\n",
    "DATE_AS_OF=date.fromisoformat('2023-06-01') #Date for analysis\n",
    "#For data visualization - date range sizes\n",
    "DATE_GROUP_DAYS=30\n",
    "CUTOFF_DAYS=90\n",
    "\n",
    "\n",
    "\n",
    "REQUIRED_COLUMNS=['user', 'date','product', 'price']\n",
    "\n",
    "#loist of recommended actions for different date threseholds\n",
    "ACTION_DATES = dict(out_of_warranty=30, obsolete=90)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T14:33:07.364198Z",
     "start_time": "2023-12-23T14:33:07.358480Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T14:33:08.917846Z",
     "start_time": "2023-12-23T14:33:08.913485Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mclean_raw\u001B[39m(df:\u001B[43mpd\u001B[49m\u001B[38;5;241m.\u001B[39mDataFrame, required_columns:[\u001B[38;5;28mstr\u001B[39m])\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39mpd\u001B[38;5;241m.\u001B[39mDataFrame:\n\u001B[1;32m      2\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03m    Check and clean purchases dataframe.  \u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03m    :param df: \u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m    :return:    updated dataframe  or exception if issue. \u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m      8\u001B[0m     missing_cols \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m(required_columns) \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mset\u001B[39m(df\u001B[38;5;241m.\u001B[39mcolumns)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def clean_raw(df:pd.DataFrame, required_columns:[str])->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Check and clean purchases dataframe.  \n",
    "    :param df: \n",
    "    :return:    updated dataframe  or exception if issue. \n",
    "    \"\"\"\n",
    "    \n",
    "    missing_cols = set(required_columns) - set(df.columns)\n",
    "    if missing_cols:\n",
    "        raise Exception(f\"Invalid dataframe Missing required columns: {', '.join(missing_cols)}\")\n",
    "    \n",
    "    #trim up - sometimes there are bad rows at the bottom of the csv. We use the first required column\n",
    "    df = df.loc[df[required_columns[0]].notnull()]\n",
    "    \n",
    "    #Error if any of the cells are blanks\n",
    "    if df.isnull().sum().sum():\n",
    "        raise Exception(f\"Invalid dataframe: some cells are empty\")\n",
    "\n",
    "    #convert dates\n",
    "    df['date']  = pd.to_datetime(df['date'], format='%Y-%m-%d').dt.date\n",
    "     \n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T14:33:09.292215Z",
     "start_time": "2023-12-23T14:33:09.271473Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(DATA_PATH)\n",
    "\n",
    "df_all=clean_raw(df_all, required_columns=REQUIRED_COLUMNS)\n",
    "LOGGER.info(\"Loaded %d clean rows from CSV[%s]\", len(df_all), DATA_PATH)\n",
    "\n",
    "#Add number of days since date.   Makes some downstream calcs a little easier\n",
    "df_all['days_ago'] = df_all['date'].apply(lambda x: (DATE_AS_OF - x).days)\n",
    "\n",
    "# Count unique values in each column\n",
    "for col in ['user', 'product']: \n",
    "    LOGGER.info(\"  # unique values in col: %s = %d\",col, df_all[col].nunique())\n",
    "\n",
    "LOGGER.info(\"Date-range min: %s\", df_all['date'].min())\n",
    "LOGGER.info(\"Date-range max: %s\", df_all['date'].max())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-23T14:32:10.294653Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_all.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-23T14:32:10.296293Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Begin to count the recommend actions. \n",
    "#sort so the largest date value is first in dict.  i.e., we want to recommend the action with the largest date range\n",
    "actions = {k: v for k, v in sorted(ACTION_DATES.items(), key=lambda item: item[1], reverse=True)} \n",
    "default='ok'\n",
    "\n",
    "\n",
    "def determine_action(days:int) ->str: \n",
    "    for action, d_thresehold in actions.items():\n",
    "        if days >= d_thresehold:\n",
    "            return action\n",
    "    return default\n",
    "\n",
    "df_all['action'] = df_all['days_ago'].apply(determine_action)\n",
    "df_all.head(5)\n",
    "\n",
    "#Find the ones beyond the dates. "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-23T14:32:10.298095Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# sort the actions by oldest\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-23T14:32:10.300007Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#####################################\n",
    "#most recent purchases per user - any product\n",
    "df_recent = df_all.sort_values(by='date', ascending=False)\n",
    "\n",
    "# group the data by Name and get the first row of each group\n",
    "df_most_recent_purchases = df_recent.groupby('user').first()\n",
    "\n",
    "df_most_recent_purchases\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-23T14:32:10.301495Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T14:32:10.303797Z",
     "start_time": "2023-12-23T14:32:10.302992Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#####################################\n",
    "#most recent purchases per user - any product\n",
    "\n",
    "df_recent = df_all.sort_values(by='date', ascending=False)\n",
    "\n",
    "# group the data by Name and get the most recent purchase (first row) of each group\n",
    "df_most_recent_purchase = df_recent.groupby(['User'],as_index=False).first()\n",
    "df_most_recent_purchase.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T14:32:10.305649Z",
     "start_time": "2023-12-23T14:32:10.304384Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#####################################\n",
    "#most recent purchases per user - list all products\n",
    "\n",
    "df_recent = df_all.sort_values(by='date', ascending=False)\n",
    "\n",
    "# group the data by Name and get the most recent purchase (first row) of each group\n",
    "df_most_recent_purchases_all = df_recent.groupby(['user', 'product'],as_index=False).first()\n",
    "df_most_recent_purchases_all.head(15)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-23T14:32:10.305865Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Find purchases that are old - such as out of warranty date.\n",
    "filtered_df = df_most_recent_purchases_all.loc[df_most_recent_purchases_all['date'] < '2023-02-01']\n",
    "\n",
    "\n",
    "print(f\"Num purchases out of warranty: {len(filtered_df)}\")\n",
    "filtered_df.head(5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-23T14:32:10.307693Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#####################################\n",
    "# Last purchase per user per product\n",
    "#\n",
    "# Note: this doesn't handle case where a user never purchased\n",
    "#####################################\n",
    "#Generate blocks of cutoff days.    The first is the max.\n",
    "dates = []\n",
    "dateblocks = {}\n",
    "\n",
    "dmin = df_all['date'].min().date()\n",
    "print(f\"dmin: Earliest entry from date: {dmin}\")\n",
    "d = DATE_AS_OF\n",
    "ndays = 0\n",
    "while d >= dmin:\n",
    " dates.insert(0,d)\n",
    "\n",
    " prevdate = d - timedelta(days=DATE_GROUP_DAYS)\n",
    " ndays_max=ndays + DATE_GROUP_DAYS-1\n",
    " dateblocks[ndays] = dict(ndays=ndays,\n",
    "                          date=d,\n",
    "                          prevdate=prevdate,\n",
    "                          ndays_max = ndays_max,\n",
    "                          label=f\"{ndays} to {ndays_max} days\")\n",
    "\n",
    " #Next block\n",
    " d = prevdate\n",
    " ndays += DATE_GROUP_DAYS\n",
    "\n",
    " #print(f\"date slice: {d}\")\n",
    " #print(f\"dateblocks: {dateblocks}\")\n",
    "\n",
    " # End up with a dict\n",
    "\n",
    " #values\n",
    " #* n days\n",
    " #* label\n",
    " #df (slice) of entries that match.\n",
    " #* be able to visualize.\n",
    "\n",
    "\n",
    " #<= 10 days:   15\n",
    " #11 <= 20 days  37\n",
    " #21"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-23T14:32:10.308675Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#dateblocks"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-23T14:32:10.309624Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all['days_since_login'] = df_all['date'].apply(lambda d: (DATE_AS_OF - d.date()).days)\n",
    "\n",
    "def calc_date_block(ndays):\n",
    "\n",
    "    for d in sorted(dateblocks.keys()):\n",
    "        #print(f\"calc_date_block d={str(d)}  v={dateblocks.get(d)}\")\n",
    "        v = dateblocks[d]\n",
    "        if ndays <= v.get('ndays_max'):\n",
    "            return v.get('label')\n",
    "    return ('unknown')\n",
    "\n",
    "df_all['days_since_label'] = df_all['days_since_login'].apply(calc_date_block)\n",
    "\n",
    "df_all.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-23T14:32:10.310680Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_date_bands = df_all.groupby('days_since_label',as_index=False).count()\n",
    "df_date_bands.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-23T14:32:10.311738Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sns.barplot(x='days_since_label', y='User', data=df_date_bands) #hue='variable')\n",
    "#plt.xticks(rotation=90)\n",
    "#plt.ylabel('Returns')\n",
    "#plt.title('Portfolio vs Benchmark Returns');"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-23T14:32:10.312919Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-23T14:32:10.313926Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-23T14:32:10.314922Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = filtered_df\n",
    "df\n",
    "\n",
    " Filter data between two dates\n",
    "filtered_df = df.loc[(df['date'] >= '2020-09-01')\n",
    "                     & (df['date'] < '2020-09-15')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-23T14:32:10.316104Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all['date'].min()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-23T14:32:10.317089Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_dict = {'a': 3, 'b': 1, 'c': 2}\n",
    "sorted_dict = {k: v for k, v in sorted(my_dict.items(), key=lambda item: item[1], reverse=True)}  # Sort by values\n",
    "print(sorted_dict)  # Output: {'b': 1, 'c': 2, 'a': 3}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-23T14:32:10.318177Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-23T14:32:10.319311Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0 (main, Oct 25 2022, 13:57:33) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
