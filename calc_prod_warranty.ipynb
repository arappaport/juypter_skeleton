{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T19:07:37.184078Z",
     "start_time": "2023-12-23T19:07:37.180900Z"
    }
   },
   "outputs": [],
   "source": [
    "#Basic notebook with a few jupyter examples - use case is calc out of date warranties\n",
    "# Load and process a CSV\n",
    "\n",
    "# Metrics to calc\n",
    " # number of product purchases that are either out of warrenty or obsolete\n",
    "# Users that haven't purchased in a while\n",
    "# Last purchase per user - any product\n",
    "\n",
    "#Last purchase per user - each product\n",
    "#  * somehow include no purchases - for ones that they have been assigned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T19:07:37.343642Z",
     "start_time": "2023-12-23T19:07:37.339839Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log level = 10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from datetime import date, timedelta\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format=\"%(message)s\")\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "LOGGER.debug(\"log level = %s\", str(LOGGER.getEffectiveLevel()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T19:07:37.600065Z",
     "start_time": "2023-12-23T19:07:37.595732Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Params - Moved these to command line or env in final version \n",
    "DATA_PATH=\"./data/purchases.csv\"\n",
    "DATE_AS_OF=date.fromisoformat('2023-06-01') #Date for analysis\n",
    "#For data visualization - date range sizes\n",
    "DATE_GROUP_DAYS=30\n",
    "CUTOFF_DAYS=90\n",
    "\n",
    "\n",
    "REQUIRED_COLUMNS=['user', 'date','product', 'price']\n",
    "\n",
    "#loist of recommended actions for different date thresholds\n",
    "ACTION_DATES = dict(out_of_warranty=30, obsolete=90)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T19:07:37.978885Z",
     "start_time": "2023-12-23T19:07:37.975966Z"
    }
   },
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "\n",
    "def clean_raw(df:pd.DataFrame, required_columns:[str])->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Check and clean purchases dataframe. Returns cleaned df or throws exception\n",
    "    :param df:   raw dataframe.   \n",
    "    :param required_columns:   List of expected columns in csv.   Any others can be deleted. \n",
    "    :return:    updated dataframe  or exception if any issue. \n",
    "    \"\"\"\n",
    "    \n",
    "    missing_cols = set(required_columns) - set(df.columns)\n",
    "    if missing_cols:\n",
    "        raise Exception(f\"Invalid CSV. Missing required columns: {', '.join(missing_cols)}\")\n",
    "    \n",
    "    #Blank check - in case CSV had blank or incomplete rows at bottom. We use the first required column to looks for nulls.      #Error if any of the cells are blanks\n",
    "    df = df.loc[df[required_columns[0]].notnull()]\n",
    "    if df.isnull().sum().sum():\n",
    "        raise Exception(f\"Invalid dataframe: some cells are empty\")\n",
    "\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T19:07:39.102361Z",
     "start_time": "2023-12-23T19:07:38.797423Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Invalid dataframe: some cells are empty",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mException\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[70], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m df_all \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(DATA_PATH)\n\u001B[0;32m----> 3\u001B[0m df_all\u001B[38;5;241m=\u001B[39m\u001B[43mclean_raw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_all\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrequired_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mREQUIRED_COLUMNS\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m#fixup convert 8601 strings to dates\u001B[39;00m\n\u001B[1;32m      5\u001B[0m df_all[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m]  \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_datetime(df_all[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mY-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mm-\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mdt\u001B[38;5;241m.\u001B[39mdate\n",
      "Cell \u001B[0;32mIn[69], line 16\u001B[0m, in \u001B[0;36mclean_raw\u001B[0;34m(df, required_columns)\u001B[0m\n\u001B[1;32m     14\u001B[0m df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mloc[df[required_columns[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39mnotnull()]\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m df\u001B[38;5;241m.\u001B[39misnull()\u001B[38;5;241m.\u001B[39msum()\u001B[38;5;241m.\u001B[39msum():\n\u001B[0;32m---> 16\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid dataframe: some cells are empty\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
      "\u001B[0;31mException\u001B[0m: Invalid dataframe: some cells are empty"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_csv(DATA_PATH)\n",
    "\n",
    "df_all=clean_raw(df_all, required_columns=REQUIRED_COLUMNS)\n",
    "#fixup convert 8601 strings to dates\n",
    "df_all['date']  = pd.to_datetime(df_all['date'], format='%Y-%m-%d').dt.date\n",
    "     \n",
    "LOGGER.info(\"Loaded %d clean rows from CSV[%s]\", len(df_all), DATA_PATH)\n",
    "\n",
    "#Add number of days since date.   Makes some downstream calcs a little easier\n",
    "df_all['days_ago'] = df_all['date'].apply(lambda x: (DATE_AS_OF - x).days)\n",
    "\n",
    "# Count unique values in each column\n",
    "for col in ['user', 'product']: \n",
    "    LOGGER.info(\"  # unique values in col: %s = %d\",col, df_all[col].nunique())\n",
    "\n",
    "LOGGER.info(\"Date-range min: %s\", df_all['date'].min())\n",
    "LOGGER.info(\"Date-range max: %s\", df_all['date'].max())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T19:07:39.443132Z",
     "start_time": "2023-12-23T19:07:39.131280Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(DATA_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T19:07:41.879051Z",
     "start_time": "2023-12-23T19:07:41.867414Z"
    }
   },
   "execution_count": 71
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=21, step=1)\n",
      "Null cells:\n",
      "Row 2, Column 4\n",
      "\n",
      "Empty strings:\n",
      "Row 1\n",
      "Row 2\n",
      "Row 3\n",
      "Row 4\n",
      "Row 5\n",
      "Row 6\n",
      "Row 7\n",
      "Row 8\n",
      "Row 9\n",
      "Row 10\n",
      "Row 11\n",
      "Row 12\n",
      "Row 13\n",
      "Row 14\n",
      "Row 15\n",
      "Row 16\n",
      "Row 17\n",
      "Row 18\n",
      "Row 19\n",
      "Row 20\n",
      "Row 21\n",
      "\n",
      "Spaces or nulls:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/y8/5nq6v40d1xj86xbp5sgqgzwc0000gn/T/ipykernel_50363/2832529895.py\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf_all\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     27\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhead\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/CloudStorage/OneDrive-Personal/src_onedrive/arappaport/juypter_skeleton/juypter_skeleton/.venv/lib/python3.9/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   6200\u001B[0m             \u001B[0;32mand\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_accessors\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6201\u001B[0m             \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_info_axis\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_can_hold_identifiers_and_holds_name\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6202\u001B[0m         ):\n\u001B[1;32m   6203\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 6204\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mobject\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__getattribute__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "df = df_all\n",
    "\n",
    "df.head(5)\n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "empty_idx=df[df.eq('')].index\n",
    "\n",
    "df.isnull().sum().sum()\n",
    "\n",
    "print(empty_idx)\n",
    "\n",
    "# Print locations of null cells\n",
    "print(\"Null cells:\")\n",
    "for row, col in zip(*df.isnull().values.nonzero()):\n",
    "    print(f\"Row {row + 1}, Column {col + 1}\")\n",
    "\n",
    "x = df[df.eq('')]\n",
    "# Print locations of empty strings\n",
    "print(\"\\nEmpty strings:\")\n",
    "for row in df[df.eq('')].index:\n",
    "    print(f\"Row {row + 1}\")\n",
    "\n",
    "# Print locations of spaces or nulls\n",
    "print(\"\\nSpaces or nulls:\")\n",
    "for row, col in zip(*df.strip().isnull().values.nonzero()):\n",
    "    print(f\"Row {row + 1}, Column {col + 1}\")\n",
    "    \n",
    "dbg = 12"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T19:07:43.438565Z",
     "start_time": "2023-12-23T19:07:43.428432Z"
    }
   },
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'days_ago'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/Library/CloudStorage/OneDrive-Personal/src_onedrive/arappaport/juypter_skeleton/juypter_skeleton/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3791\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3790\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3791\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3792\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32mindex.pyx:152\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mindex.pyx:181\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'days_ago'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[73], line 13\u001B[0m\n\u001B[1;32m     10\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m action\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m default\n\u001B[0;32m---> 13\u001B[0m df_all[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maction\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdf_all\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdays_ago\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mapply(determine_action)\n\u001B[1;32m     14\u001B[0m df_all\u001B[38;5;241m.\u001B[39mhead(\u001B[38;5;241m5\u001B[39m)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m#Find the ones beyond the dates. \u001B[39;00m\n",
      "File \u001B[0;32m~/Library/CloudStorage/OneDrive-Personal/src_onedrive/arappaport/juypter_skeleton/juypter_skeleton/.venv/lib/python3.9/site-packages/pandas/core/frame.py:3893\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3891\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3892\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3893\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3894\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3895\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/Library/CloudStorage/OneDrive-Personal/src_onedrive/arappaport/juypter_skeleton/juypter_skeleton/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3798\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3793\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m   3794\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[1;32m   3795\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[1;32m   3796\u001B[0m     ):\n\u001B[1;32m   3797\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[0;32m-> 3798\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3799\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3800\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3801\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3802\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3803\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'days_ago'"
     ]
    }
   ],
   "source": [
    "# Begin to count the recommend actions. \n",
    "#sort so the largest date value is first in dict.  i.e., we want to recommend the action with the largest date range\n",
    "actions = {k: v for k, v in sorted(ACTION_DATES.items(), key=lambda item: item[1], reverse=True)} \n",
    "default='ok'\n",
    "\n",
    "\n",
    "def determine_action(days:int) ->str: \n",
    "    for action, d_thresehold in actions.items():\n",
    "        if days >= d_thresehold:\n",
    "            return action\n",
    "    return default\n",
    "\n",
    "df_all['action'] = df_all['days_ago'].apply(determine_action)\n",
    "df_all.head(5)\n",
    "\n",
    "#Find the ones beyond the dates. "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T19:07:45.254651Z",
     "start_time": "2023-12-23T19:07:44.470110Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# sort the actions by oldest\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#####################################\n",
    "#most recent purchases per user - any product\n",
    "df_recent = df_all.sort_values(by='date', ascending=False)\n",
    "\n",
    "# group the data by Name and get the first row of each group\n",
    "df_most_recent_purchases = df_recent.groupby('user').first()\n",
    "\n",
    "df_most_recent_purchases\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#####################################\n",
    "#most recent purchases per user - any product\n",
    "\n",
    "df_recent = df_all.sort_values(by='date', ascending=False)\n",
    "\n",
    "# group the data by Name and get the most recent purchase (first row) of each group\n",
    "df_most_recent_purchase = df_recent.groupby(['user'],as_index=False).first()\n",
    "df_most_recent_purchase.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#####################################\n",
    "#most recent purchases per user - list all products\n",
    "\n",
    "df_recent = df_all.sort_values(by='date', ascending=False)\n",
    "\n",
    "# group the data by Name and get the most recent purchase (first row) of each group\n",
    "df_most_recent_purchases_all = df_recent.groupby(['user', 'product'],as_index=False).first()\n",
    "df_most_recent_purchases_all.head(15)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Find purchases that are old - such as out of warranty date.\n",
    "filtered_df = df_most_recent_purchases_all.loc[df_most_recent_purchases_all['date'] < '2023-02-01']\n",
    "\n",
    "\n",
    "print(f\"Num purchases out of warranty: {len(filtered_df)}\")\n",
    "filtered_df.head(5)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#####################################\n",
    "# Last purchase per user per product\n",
    "#\n",
    "# Note: this doesn't handle case where a user never purchased\n",
    "#####################################\n",
    "#Generate blocks of cutoff days.    The first is the max.\n",
    "dates = []\n",
    "dateblocks = {}\n",
    "\n",
    "#dmin = df_all['date'].min().date()\n",
    "dmin = df_all['date'].min()\n",
    "print(f\"dmin: Earliest entry from date: {dmin}\")\n",
    "d = DATE_AS_OF\n",
    "ndays = 0\n",
    "while d >= dmin:\n",
    " dates.insert(0,d)\n",
    "\n",
    " prevdate = d - timedelta(days=DATE_GROUP_DAYS)\n",
    " ndays_max=ndays + DATE_GROUP_DAYS-1\n",
    " dateblocks[ndays] = dict(ndays=ndays,\n",
    "                          date=d,\n",
    "                          prevdate=prevdate,\n",
    "                          ndays_max = ndays_max,\n",
    "                          label=f\"{ndays} to {ndays_max} days\")\n",
    "\n",
    " #Next block\n",
    " d = prevdate\n",
    " ndays += DATE_GROUP_DAYS\n",
    "\n",
    " #print(f\"date slice: {d}\")\n",
    " #print(f\"dateblocks: {dateblocks}\")\n",
    "\n",
    " # End up with a dict\n",
    "\n",
    " #values\n",
    " #* n days\n",
    " #* label\n",
    " #df (slice) of entries that match.\n",
    " #* be able to visualize.\n",
    "\n",
    "\n",
    " #<= 10 days:   15\n",
    " #11 <= 20 days  37\n",
    " #21"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#dateblocks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#df_all['days_since_login'] = df_all['date'].apply(lambda d: (DATE_AS_OF - d.date()).days)\n",
    "\n",
    "def calc_date_block(ndays):\n",
    "\n",
    "    for d in sorted(dateblocks.keys()):\n",
    "        #print(f\"calc_date_block d={str(d)}  v={dateblocks.get(d)}\")\n",
    "        v = dateblocks[d]\n",
    "        if ndays <= v.get('ndays_max'):\n",
    "            return v.get('label')\n",
    "    return ('unknown')\n",
    "\n",
    "df_all['days_since_label'] = df_all['days_ago'].apply(calc_date_block)\n",
    "\n",
    "df_all.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_date_bands = df_all.groupby('days_since_label',as_index=False).count()\n",
    "df_date_bands.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sns.barplot(x='days_since_label', y='user', data=df_date_bands) #hue='variable')\n",
    "#plt.xticks(rotation=90)\n",
    "#plt.ylabel('Returns')\n",
    "#plt.title('Portfolio vs Benchmark Returns');"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "       A           B               C\n0  EMpty  whitespace  None and empty\n1                 xx            None\n2      3           6               9\n3      4                            ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>EMpty</td>\n      <td>whitespace</td>\n      <td>None and empty</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>xx</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>6</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T16:42:21.360401Z",
     "start_time": "2023-12-23T16:42:21.353596Z"
    }
   },
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def trim_all(df:pd.DataFrame):\n",
    "    df_trimmed = df.map(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    return df_trimmed"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T16:42:24.324475Z",
     "start_time": "2023-12-23T16:42:24.310505Z"
    }
   },
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def find_blanks(df):\n",
    "    # Print locations of null cells\n",
    "    print(\"Null cells:\")\n",
    "    for row, col in zip(*df.isnull().values.nonzero()):\n",
    "        print(f\"Row {row + 1}, Column {col + 1}\")\n",
    "\n",
    "    # Print locations of empty strings\n",
    "    print(\"\\nEmpty strings:\")\n",
    "    for row in df[df.eq('')].index:\n",
    "        print(f\"Row {row + 1}\")\n",
    "\n",
    "    # Print locations of spaces or nulls\n",
    "#    print(\"\\nSpaces or nulls:\")\n",
    "#    for row, col in zip(*df.str.strip().isnull().values.nonzero()):\n",
    "#        print(f\"Row {row + 1}, Column {col + 1}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T16:42:25.656728Z",
     "start_time": "2023-12-23T16:42:25.646300Z"
    }
   },
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before - time_all\n",
      "       A           B               C\n",
      "0  EMpty  whitespace  None and empty\n",
      "1                 xx            None\n",
      "2      3           6               9\n",
      "3      4                            \n",
      "Null cells:\n",
      "Row 2, Column 3\n",
      "\n",
      "Empty strings:\n",
      "Row 1\n",
      "Row 2\n",
      "Row 3\n",
      "Row 4\n"
     ]
    }
   ],
   "source": [
    "print(\"before - time_all\")\n",
    "print(df.head(20))\n",
    "find_blanks(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T16:42:27.215354Z",
     "start_time": "2023-12-23T16:42:27.201642Z"
    }
   },
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after - trim_all\n",
      "       A           B               C\n",
      "0  EMpty  whitespace  None and empty\n",
      "1                 xx            None\n",
      "2      3           6               9\n",
      "3      4                            \n",
      "Null cells:\n",
      "Row 2, Column 3\n",
      "\n",
      "Empty strings:\n",
      "Row 1\n",
      "Row 2\n",
      "Row 3\n",
      "Row 4\n"
     ]
    }
   ],
   "source": [
    "print(\"after - trim_all\")\n",
    "df_trimmed = trim_all(df)\n",
    "print(df_trimmed.head(20))\n",
    "find_blanks(df_trimmed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T16:42:28.079376Z",
     "start_time": "2023-12-23T16:42:28.075820Z"
    }
   },
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows with blanks\n",
      "   A   B     C\n",
      "1     xx  None\n",
      "3  4          \n",
      "empty_cols\n",
      "Index(['A', 'C'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Find rows with empty strings in any column\n",
    "empty_rows = df[df.eq('').any(axis=1)]\n",
    "print('rows with blanks')\n",
    "print(empty_rows)\n",
    "\n",
    "# Find columns with empty strings\n",
    "empty_cols = df.columns[df.eq('').any()]\n",
    "print('empty_cols')\n",
    "print(empty_cols)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T16:42:56.353243Z",
     "start_time": "2023-12-23T16:42:56.337048Z"
    }
   },
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "0"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0 (main, Oct 25 2022, 13:57:33) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
